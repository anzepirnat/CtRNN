{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85af5f61-4cd2-41ef-9495-024fa393aafa",
   "metadata": {
    "tags": []
   },
   "source": [
    "<span style=\"color: blue; font-size: 30px;\">Contents:</span>\n",
    "\n",
    "<hr> <!-- Horizontal Rule using HTML -->\n",
    "\n",
    "<ol>\n",
    "  <li><strong>Install & Import Dependencies</strong></li>\n",
    "  <li><strong>Functions</strong></li>\n",
    "  <li><strong>Architectures</strong></li>\n",
    "  <li>\n",
    "    <strong>Generating Datasets</strong>\n",
    "    <ol>\n",
    "      <li>General Data Processing</li>\n",
    "      <li>RE</li>\n",
    "      <li>SE</li>\n",
    "    </ol>\n",
    "  </li>\n",
    "  <li>\n",
    "    <strong>Training & Evaluation</strong>\n",
    "    <ol>\n",
    "      <li>RE</li>\n",
    "      <li>SE</li>\n",
    "    </ol>\n",
    "  </li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8fa4998-8c73-4f55-afd9-c080505f442a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Install & Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4784a9c6-e2e6-4fc3-9e3c-94faf38fedf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e5ba9c75-56c1-4925-a47a-b7f4dd838b16",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/nilmtk/nilmtk@master\n",
      "  Cloning https://github.com/nilmtk/nilmtk (to revision master) to /tmp/pip-req-build-9275vbuz\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/nilmtk/nilmtk /tmp/pip-req-build-9275vbuz\n",
      "  Resolved https://github.com/nilmtk/nilmtk to commit 2ab4427e7c44732d547affc7790acb3da98ea4c6\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: nilmtk\n",
      "  Building wheel for nilmtk (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for nilmtk: filename=nilmtk-0.4.0.dev1+git.2ab4427-py3-none-any.whl size=279179 sha256=5a6987a29488e21ecb58594760c899b94e35c07fd4b04df97c01eddc4ef5e067\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-1_h5bqfd/wheels/05/a4/8e/b767c3d1714f61fd30ec991c25780be8cc04c474da8205aeee\n",
      "Successfully built nilmtk\n",
      "Installing collected packages: nilmtk\n",
      "Successfully installed nilmtk-0.4.0.dev1+git.2ab4427\n",
      "Collecting git+https://github.com/nilmtk/nilm_metadata@master\n",
      "  Cloning https://github.com/nilmtk/nilm_metadata (to revision master) to /tmp/pip-req-build-pk5o0oqe\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/nilmtk/nilm_metadata /tmp/pip-req-build-pk5o0oqe\n",
      "  Resolved https://github.com/nilmtk/nilm_metadata to commit 7ed4bab9062d04cb35c6b6000b451715dc5ab4af\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: nilm-metadata\n",
      "  Building wheel for nilm-metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for nilm-metadata: filename=nilm_metadata-0.2.5-py3-none-any.whl size=24340 sha256=5f5868923f3b0c73a69a1d32f3b4403ceec8e1eaedc40b5a4728a54260dc1cac\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-dpmxysvg/wheels/7e/2f/7f/e41975c202542dbc11228875ff8473ed4cb95e04a274222bb7\n",
      "Successfully built nilm-metadata\n",
      "Installing collected packages: nilm-metadata\n",
      "Successfully installed nilm-metadata-0.2.5\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (4.66.2)\n",
      "Requirement already satisfied: tensorflow[and-cuda] in /opt/conda/lib/python3.10/site-packages (2.15.0.post1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow[and-cuda]) (1.6.3)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow[and-cuda]) (0.36.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow[and-cuda]) (2.4.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow[and-cuda]) (4.21.10)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow[and-cuda]) (2.1.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow[and-cuda]) (21.3)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow[and-cuda]) (16.0.6)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow[and-cuda]) (0.2.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /opt/conda/lib/python3.10/site-packages (from tensorflow[and-cuda]) (1.23.5)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow[and-cuda]) (3.7.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow[and-cuda]) (3.3.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow[and-cuda]) (65.5.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow[and-cuda]) (2.15.0)\n",
      "Requirement already satisfied: keras<2.16,>=2.15.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow[and-cuda]) (2.15.0)\n",
      "Requirement already satisfied: tensorboard<2.16,>=2.15 in /opt/conda/lib/python3.10/site-packages (from tensorflow[and-cuda]) (2.15.2)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow[and-cuda]) (4.4.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow[and-cuda]) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow[and-cuda]) (1.62.0)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow[and-cuda]) (0.5.4)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /opt/conda/lib/python3.10/site-packages (from tensorflow[and-cuda]) (23.5.26)\n",
      "Requirement already satisfied: ml-dtypes~=0.2.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow[and-cuda]) (0.2.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow[and-cuda]) (1.14.1)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.4.25 in /opt/conda/lib/python3.10/site-packages (from tensorflow[and-cuda]) (8.9.4.25)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.2.141 in /opt/conda/lib/python3.10/site-packages (from tensorflow[and-cuda]) (12.1.2.141)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.5.2.141 in /opt/conda/lib/python3.10/site-packages (from tensorflow[and-cuda]) (11.5.2.141)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.2.140 in /opt/conda/lib/python3.10/site-packages (from tensorflow[and-cuda]) (12.2.140)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.2.5.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow[and-cuda]) (12.2.5.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.2.140 in /opt/conda/lib/python3.10/site-packages (from tensorflow[and-cuda]) (12.2.140)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.3.141 in /opt/conda/lib/python3.10/site-packages (from tensorflow[and-cuda]) (10.3.3.141)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.8.103 in /opt/conda/lib/python3.10/site-packages (from tensorflow[and-cuda]) (11.0.8.103)\n",
      "Requirement already satisfied: nvidia-cuda-nvcc-cu12==12.2.140 in /opt/conda/lib/python3.10/site-packages (from tensorflow[and-cuda]) (12.2.140)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.2.140 in /opt/conda/lib/python3.10/site-packages (from tensorflow[and-cuda]) (12.2.140)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.2.142 in /opt/conda/lib/python3.10/site-packages (from tensorflow[and-cuda]) (12.2.142)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.16.5 in /opt/conda/lib/python3.10/site-packages (from tensorflow[and-cuda]) (2.16.5)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow[and-cuda]) (0.38.4)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow[and-cuda]) (3.5.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow[and-cuda]) (1.2.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow[and-cuda]) (2.28.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow[and-cuda]) (3.0.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow[and-cuda]) (0.7.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow[and-cuda]) (2.28.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->tensorflow[and-cuda]) (3.0.9)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow[and-cuda]) (4.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow[and-cuda]) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow[and-cuda]) (0.3.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow[and-cuda]) (1.3.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow[and-cuda]) (2022.9.24)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow[and-cuda]) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow[and-cuda]) (1.26.13)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow[and-cuda]) (3.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow[and-cuda]) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow[and-cuda]) (0.5.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow[and-cuda]) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall -y -q nilmtk nilm_metadata\n",
    "!python3 -m pip install --no-deps git+https://github.com/nilmtk/nilmtk@master\n",
    "!python3 -m pip install --no-deps git+https://github.com/nilmtk/nilm_metadata@master\n",
    "!pip install tqdm\n",
    "\n",
    "#!mamba install tensorflow-gpu==2.11.0 -y -q\n",
    "!pip install tensorflow[and-cuda]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0eb3e1ae-3c71-4f89-8708-a8efe8d4b6e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Using cached xgboost-2.0.3-py3-none-manylinux2014_x86_64.whl (297.1 MB)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from xgboost) (1.23.5)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from xgboost) (1.9.3)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-2.0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-22 11:34:01.950497: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-22 11:34:01.950546: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-22 11:34:01.951742: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-02-22 11:34:01.957544: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-22 11:34:02.579584: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA A100 80GB PCIe MIG 3g.40gb, compute capability 8.0\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "from nilmtk import DataSet\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from joblib import Memory\n",
    "import pickle\n",
    "from pprint import pprint\n",
    "\n",
    "import multiprocessing as mp\n",
    "\n",
    "from typing import Dict\n",
    "\n",
    "!pip install -q scikit-learn-intelex\n",
    "from sklearn import pipeline, metrics, linear_model, model_selection, multioutput, tree, ensemble, neural_network\n",
    "\n",
    "!pip install xgboost\n",
    "import xgboost as xgb\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import keras\n",
    "from sklearn.utils import class_weight\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation, Conv2D, MaxPooling2D, BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import multilabel_confusion_matrix, classification_report, confusion_matrix\n",
    "\n",
    "from matplotlib import pyplot as plt \n",
    "\n",
    "# GPU boost\n",
    "from tensorflow.keras import mixed_precision\n",
    "mixed_precision.set_global_policy('mixed_float16')\n",
    "\n",
    "memory = Memory(location='./cache')\n",
    "\n",
    "import numpy as np\n",
    "import warnings\n",
    "import math\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Flatten, Dense, Input, GRU, BatchNormalization, LSTM, Bidirectional, AveragePooling1D\n",
    "from keras.layers import Conv1D, Conv1DTranspose, LocallyConnected1D, SeparableConv1D, ConvLSTM1D\n",
    "from keras.layers import MaxPooling1D, Dropout\n",
    "from keras.layers import GlobalMaxPooling1D\n",
    "from keras.layers import GlobalAveragePooling1D\n",
    "from keras.preprocessing import image\n",
    "#from keras.utils import layer_utils\n",
    "#from keras.utils.data_utils import get_file\n",
    "from keras import backend as K\n",
    "from keras.applications.imagenet_utils import decode_predictions\n",
    "from keras.applications.imagenet_utils import preprocess_input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca83bc0-fe91-4cf0-a435-f07c11cfde8a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89327a9-72f1-4d58-b0dc-65cc5a840f59",
   "metadata": {},
   "source": [
    "<p> To load raw datasets we used the following functions. They expect datasets in .hdf5 format. </p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4aa2f6b5-3560-47e9-816c-15d59773783d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@memory.cache\n",
    "\n",
    "def load_refit_dataset():\n",
    "    try:\n",
    "        dataset = DataSet('./refit.hdf5')\n",
    "\n",
    "        samples = []\n",
    "        for building_idx, building in dataset.buildings.items():\n",
    "            for meter in building.elec.all_meters():\n",
    "\n",
    "                data = list(meter.load())\n",
    "                assert len(data) == 1\n",
    "\n",
    "                assert len(meter.appliances) < 2\n",
    "\n",
    "                sample = (building_idx, list([a.type['type'] for a in meter.appliances]), data, meter.good_sections())\n",
    "\n",
    "                samples.append(sample)\n",
    "                \n",
    "        return samples\n",
    "\n",
    "    except Exception as e:\n",
    "        dataset.store.close()\n",
    "        raise e\n",
    "        \n",
    "def load_ukdale_dataset():\n",
    "    try:\n",
    "        dataset = DataSet('./ukdale.hdf5')\n",
    "\n",
    "        samples = []\n",
    "        for building_idx, building in dataset.buildings.items():\n",
    "            for meter in building.elec.all_meters():\n",
    "\n",
    "                data = list(meter.load())\n",
    "                assert len(data) == 1\n",
    "\n",
    "                sample = (building_idx, list([a.type['type'] for a in meter.appliances]), data, meter.good_sections())\n",
    "\n",
    "                samples.append(sample)\n",
    "                \n",
    "        return samples\n",
    "\n",
    "    except Exception as e:\n",
    "        dataset.store.close()\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee0fa5c-f4f2-4801-ab00-340609e06159",
   "metadata": {},
   "source": [
    "<p> The 2 cells below contain function that will be used to process data into x_train, x_test, y_train, y_test, labels format in Section 4 of this notebook. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa7f9cbf-eacb-41e9-a8af-3753fe3a75fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preparation(dataset):\n",
    "    X = defaultdict(lambda: [])\n",
    "\n",
    "    for (idx, appliances, data, good_sections) in dataset:\n",
    "        if not appliances:\n",
    "            continue\n",
    "            \n",
    "        appliance = appliances[0]\n",
    "        data = data[0]\n",
    "    \n",
    "        samples = [data[good.start:good.end] for good in good_sections]\n",
    "        X[appliance].extend(samples)\n",
    "        \n",
    "    for appliance, samples in X.items():\n",
    "        print(appliance, len(samples))\n",
    "        \n",
    "    return X\n",
    "\n",
    "\n",
    "def test_appliance_augmentator(augmentator, *args, **kwargs):\n",
    "    X, y, labels = next(augmentator(processed_data, *args, **kwargs))\n",
    "\n",
    "    f, ax = plt.subplots()\n",
    "    ax.set_title('Augmented time-series')\n",
    "    ax.plot(X)\n",
    "    f.show()\n",
    "    \n",
    "    \n",
    "    \n",
    "    n_appliances = kwargs.get('n_appliances_per_sample', None)\n",
    "    f, ax = plt.subplots()\n",
    "\n",
    "    \n",
    "    print('Number of positive datapoints per appliance')\n",
    "    for mask, label in zip(y, labels):\n",
    "        if np.sum(mask) == 0:\n",
    "            continue\n",
    "        \n",
    "        print(f'{label}:\\t {np.sum(mask)}')\n",
    "        \n",
    "\n",
    "        tmp = X.copy()\n",
    "        tmp[~mask] = 0\n",
    "        ax.plot(tmp, linestyle=None, marker='.', label=label, alpha=0.5)\n",
    "        #ax.plot(np.ma.masked_where(mask, np.full_like(X, idx)), marker='.', label=label)\n",
    "    \n",
    "\n",
    "    f.legend(title='markers based on mask')\n",
    "    f.show()\n",
    "    \n",
    "from typing import Iterator, List, Tuple\n",
    "\n",
    "def appliance_augmentator(dataset:Dict[str,list], sample_length:int, n_appliances_per_sample:int, random_state:int=None) -> Iterator[Tuple[np.ndarray, np.ndarray, List[str]]]:\n",
    "    \n",
    "    # Initialize seeded random number generator\n",
    "    rng = np.random.default_rng(seed=random_state)\n",
    "    \n",
    "    # How many appliances are mixed together\n",
    "    N = n_appliances_per_sample\n",
    "    \n",
    "    # Sample length / Window size\n",
    "    L = sample_length\n",
    "    \n",
    "    # Noise floor\n",
    "    NOISE_FLOOR = 20.0\n",
    "    \n",
    "    # Get all available appliances\n",
    "    appliance_names = tuple(dataset.keys())\n",
    "    \n",
    "    # How many appliances are there?\n",
    "    n_appliances = len(appliance_names)\n",
    "    print(\"Number of appliances: \", n_appliances)\n",
    "    # Start endless generator of samples\n",
    "    while True:\n",
    "        # pre-allocate array for time series\n",
    "        series = np.zeros(L, dtype=np.float64)\n",
    "        \n",
    "        # pre-allocate boolean array for masks\n",
    "        labels = np.zeros((n_appliances, L), dtype=bool)\n",
    "        \n",
    "        # Select N random appliances (no replace, because same appliance should not appear twice in the same sample)\n",
    "        for appliance_idx in rng.choice(n_appliances, size=N, replace=False):\n",
    "            appliance_name = appliance_names[appliance_idx]\n",
    "\n",
    "            # Pick random sample of a selected appliance\n",
    "            n_available_samples = len(dataset[appliance_name])\n",
    "            sample_idx = rng.choice(n_available_samples)\n",
    "            \n",
    "            # retrieve sample as NumPy array with appropriate dimensions\n",
    "            sample_series = dataset[appliance_name][sample_idx].iloc[:].to_numpy().squeeze(axis=-1)\n",
    "            \n",
    "            # If sample is too short (shorter than L), give padding on both sides.\n",
    "            if len(sample_series) <= L:\n",
    "                padding = L // 2\n",
    "                sample_series = np.pad(sample_series, (padding, padding), mode='constant', constant_values=0)\n",
    "            \n",
    "            \n",
    "            # The total length of sample time-series\n",
    "            sample_len = len(sample_series)\n",
    "            \n",
    "            # Sanity check(s)\n",
    "            assert sample_len >= L, f'Sample length should be equal or larger than L: {sample_len} >= {L}'\n",
    "            \n",
    "            sample_offset = rng.choice(sample_len - L)\n",
    "            \n",
    "            sample = sample_series[sample_offset:sample_offset+L]\n",
    "            \n",
    "            mask = sample > NOISE_FLOOR  # find samples that are above noise floor\n",
    "            \n",
    "            series[:] += sample\n",
    "            labels[appliance_idx, :] |= mask  # logical ORing the mask\n",
    "            \n",
    "        # Add random (constant) offset\n",
    "        #series += rng.random() * (NOISE_FLOOR)\n",
    "            \n",
    "        # There has to be two samples present. Even though we combined two subsets, one or both could be empty.\n",
    "        # Workaround until area of interest is implemented.\n",
    "        if not (np.sum([(np.any(label) > 0) for label in labels]) == N):\n",
    "            continue\n",
    "            \n",
    "        yield series, labels, appliance_names\n",
    "        \n",
    "        \n",
    "        \n",
    "import multiprocessing as mp\n",
    "\n",
    "\n",
    "\n",
    "def process(random_state):\n",
    "    # Initialize internal seeded random number generator\n",
    "    rng = np.random.default_rng(seed=random_state)\n",
    "    \n",
    "    # Try to generate valid sample\n",
    "    #while True:\n",
    "    # pre-allocate array for time series\n",
    "    series = np.zeros(L, dtype=np.float64)\n",
    "\n",
    "    # pre-allocate boolean array for masks\n",
    "    labels = np.zeros((n_appliances, L), dtype=bool)\n",
    "\n",
    "    # Select N random appliances (no replace, because same appliance should not appear twice in the same sample)\n",
    "    # h\n",
    "    for appliance_idx in rng.choice(n_appliances, size=N, replace=False):\n",
    "        appliance_name = appliance_names[appliance_idx]\n",
    "\n",
    "        # Pick random sample of a selected appliance\n",
    "        n_available_samples = len(dataset[appliance_name])\n",
    "        sample_idx = rng.choice(n_available_samples)\n",
    "\n",
    "        # retrieve sample as NumPy array with appropriate dimensions\n",
    "        try:\n",
    "            sample_series = dataset[appliance_name][sample_idx].iloc[:].to_numpy().squeeze(axis=-1)\n",
    "        except ValueError:\n",
    "            continue\n",
    "\n",
    "        # If sample is too short (shorter than L), give padding on both sides.\n",
    "        if len(sample_series) <= L:\n",
    "            padding = L // 2\n",
    "            sample_series = np.pad(sample_series, (padding, padding), mode='constant', constant_values=0)\n",
    "\n",
    "\n",
    "        # The total length of sample time-series\n",
    "        sample_len = len(sample_series)\n",
    "\n",
    "        # Sanity check(s)\n",
    "        assert sample_len >= L, f'Sample length should be equal or larger than L: {sample_len} >= {L}'\n",
    "\n",
    "        while True:\n",
    "            sample_offset = rng.choice(sample_len - L)\n",
    "            sample = sample_series[sample_offset:sample_offset+L]\n",
    "            \n",
    "            mask = sample > NOISE_FLOOR  # find samples that are above noise floor\n",
    "            \n",
    "            if np.any(mask):\n",
    "                break\n",
    "\n",
    "\n",
    "\n",
    "        series[:] += sample\n",
    "        labels[appliance_idx, :] |= mask  # logical ORing the mask\n",
    "\n",
    "    # There has to be two samples present. Even though we combined two subsets, one or both could be empty.\n",
    "    # Workaround until area of interest is implemented.\n",
    "    #if (np.sum([(np.any(label) > 0) for label in labels]) == N):\n",
    "    #    break\n",
    "\n",
    "    return series, labels, appliance_names\n",
    "            \n",
    "\n",
    "\n",
    "def parallel_appliance_augmentator(_dataset:Dict[str,list], sample_length:int, n_appliances_per_sample:int, n_samples:int, random_state:int=None) -> list:\n",
    "    import sys\n",
    "    \n",
    "    global N, L, NOISE_FLOOR, appliance_names, n_appliances, dataset\n",
    "    \n",
    "    dataset = _dataset\n",
    "\n",
    "    # How many appliances are mixed together\n",
    "    N = n_appliances_per_sample\n",
    "\n",
    "    # Sample length / Window size\n",
    "    L = sample_length\n",
    "\n",
    "    # Noise floor\n",
    "    NOISE_FLOOR = 20.0\n",
    "\n",
    "    # Get all available appliances\n",
    "    appliance_names = tuple(dataset.keys())\n",
    "\n",
    "    # How many appliances are there?\n",
    "    n_appliances = len(appliance_names)\n",
    "    \n",
    "    # if random_state is not defined, generate it on the fly\n",
    "    if random_state == None:\n",
    "        random_state = np.random.randint(0, sys.maxsize)\n",
    "            \n",
    "    with mp.Pool() as pool:\n",
    "        outputs = pool.map(process, np.arange(n_samples) + random_state)\n",
    "        \n",
    "    return tuple(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "577142a6-0769-4235-a04a-3f047593ec9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def DevicesDataXY(number_of_datasets: int, \n",
    "                  number_of_devices_in_datasets: int, \n",
    "                  number_of_all_devices: int):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        number_of_dataset (int): a number of datasets used, we use multiple datasets in the Dictlist to evaluate different randomly generated datasets\n",
    "        number_of_devices_in_datasets (int): a number of devices in total (DiT) that will be present in the dataset\n",
    "        number_of_all_devices (int): number of all devices that are available for the dataset\n",
    "        \n",
    "    Returns:\n",
    "        devicesX_Y (list)\n",
    "        dataX_Y (list)\n",
    "    \n",
    "    This function uses processed_data and shapes it into two lists \n",
    "    one of them contains data from devices (dataX_Y) and one of them names of devices (devicesX_Y).\n",
    "    Lists contain multiple datasets specified with number_of_datasets, all of which have \n",
    "    the same number of devices in them, specified by number_of_devices_in_datasets.\n",
    "    We choose devices for datasets randomly, thus we have to specify the number of all devices in the REFIT (22) or UKDALE dataset (54).\n",
    "    \"\"\"\n",
    "    \n",
    "    # we extract the dictionary processed_data into a list AllTable\n",
    "    AllTable = [[k,v] for k,v in processed_data.items()]\n",
    "    \n",
    "    devicesX_Y = []\n",
    "    dataX_Y = []\n",
    "    \n",
    "    # for loop goes over all datasets\n",
    "    for i in range(0,number_of_datasets):    \n",
    "        devicesY = []\n",
    "        dataY = []\n",
    "        j = 0\n",
    "        \n",
    "        # while loop goes over all devices in datasets\n",
    "        while j < number_of_devices_in_datasets:\n",
    "            \n",
    "            # we get a random number with random library\n",
    "            random_number = random.randrange(number_of_all_devices)\n",
    "            \n",
    "            # we use the random number to get a random device and random data that belongs to it from AllTable\n",
    "            random_device = AllTable[random_number][0]\n",
    "            random_data = AllTable[random_number][1]\n",
    "            \n",
    "            # we append the device and its data if it doesn't already exist \n",
    "            # and thus avoid having the same device more then once in the same dataset\n",
    "            if random_device not in devicesY:\n",
    "                devicesY.append(random_device)\n",
    "                dataY.append(random_data)\n",
    "                j += 1\n",
    "        \n",
    "        devicesX_Y.append(devicesY)\n",
    "        dataX_Y.append(dataY)\n",
    "    \n",
    "    return devicesX_Y, dataX_Y\n",
    "\n",
    "\n",
    "def ListsToDictlist(devices: list, data: list, number_of_devices: int):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function takes lists from DevicesDataXY or DevicesDataHoly5 and\n",
    "    turns each of the sublists into a dictionary and then appends those dicitonaries into a list. \n",
    "    \n",
    "    Args:\n",
    "        devices (list): a list of devices {devicesX_Y}\n",
    "        data (list): a list of data from devices {dataX_Y}\n",
    "        number_of_devices (int): \n",
    "        \n",
    "    Returns:\n",
    "        Dictlist (dict): a dictionary of lists\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    Dictlist=[]\n",
    "    \n",
    "    # we make dictionaries out of lists that we input and append them to list of dictionaries (Dictlist)\n",
    "    for i in range(0,number_of_devices):\n",
    "        dictionary=dict(zip(devices[i], data[i]))\n",
    "        Dictlist.append(dictionary)\n",
    "        \n",
    "    return Dictlist\n",
    "\n",
    "\n",
    "def GenerateXXYYL(Dictlist: list, \n",
    "              sample_length: int, \n",
    "              n_appliances_per_sample: int, \n",
    "              dataset_number: int,\n",
    "              number_of_generated_samples: int\n",
    "                     ):\n",
    "    \n",
    "    \"\"\"\n",
    "    Args:\n",
    "        Dictlist (list): a list of dicitionaries generated by function ListsToDictlist\n",
    "        sample_length (int): length of samples aka. length of the timewindow, we use 2550 as proposed and explained by Tanoni et al.\n",
    "        dataset_number (int): number of the dataset, we have multiple datasets in the Dictlist to evaluate different randomly generated datasets\n",
    "        n_appliances_per_sample (int): number of active devices (AD)\n",
    "        number_of_generated_samples (int): number of all samples generated, so len(x_train) + len(x_test)\n",
    "\n",
    "    Returns:\n",
    "        x_train\n",
    "        x_test\n",
    "        y_train\n",
    "        y_test\n",
    "        labels\n",
    "    \"\"\" \n",
    "    \n",
    "    X, Y, labels = [], [], None\n",
    "    \n",
    "    generator = parallel_appliance_augmentator(Dictlist[dataset_number], \n",
    "                                      sample_length=sample_length, \n",
    "                                      n_appliances_per_sample=n_appliances_per_sample,\n",
    "                                      n_samples=number_of_generated_samples,\n",
    "                                      random_state=0xDEADBEEF)\n",
    "    \n",
    "    for idx, (_x, _y, labels) in zip(range(number_of_generated_samples), generator):\n",
    "        X.append(_x), Y.append(_y)\n",
    "        \n",
    "    X, Y = np.asarray(X), np.asarray(Y)\n",
    "    y = np.any(Y, axis=-1) > 0\n",
    "    sample_weight = np.sum(Y, axis=-1) / 128\n",
    "    \n",
    "    # split into train test sets\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "    \n",
    "    # add the needed dimension\n",
    "    x_train = np.expand_dims(x_train, -1)\n",
    "    x_test = np.expand_dims(x_test, -1)\n",
    "    \n",
    "    return x_train, x_test, y_train, y_test, labels\n",
    "\n",
    "\n",
    "\n",
    "def GenerateRandomXXYYL(Dictlist: list, \n",
    "              sample_length: int,  \n",
    "              dataset_number: int,\n",
    "              table_of_options: list,\n",
    "              number_of_generated_samples: int\n",
    "              ):\n",
    "    \n",
    "    \"\"\"\n",
    "    Args:\n",
    "        Dictlist (list): a list of dicitionaries generated by function ListsToDictlist\n",
    "        sample_length (int): length of samples aka. length of the timewindow, we use 2550 as proposed and explained by Tanoni et al.\n",
    "        dataset_number (int): number of the dataset, we have multiple datasets in the Dictlist to evaluate different randomly generated datasets\n",
    "        table_of_options (list): a list of possible active devices (AD)\n",
    "        number_of_generated_samples (int): a number of samples that we generate, we use 120_000\n",
    "    \n",
    "    Returns:\n",
    "        x_train\n",
    "        x_test\n",
    "        y_train\n",
    "        y_test\n",
    "        labels\n",
    "        \n",
    "        These datasets consist of equal parts of options from table of options.\n",
    "        EX: If you have table_of_options = [1,2,3,4] the dataset will be 1/4 data with 1 active device, 1/4 data with 2 active devices, ...\n",
    "        Dataset is mixed so that samples are randomly dispersed throughout the dataset\n",
    "    \"\"\"\n",
    "    \n",
    "    from tqdm import tqdm\n",
    "    from multiprocessing import Pool\n",
    "    \n",
    "    print('Generating datasets with variable active devices ...')\n",
    "    \n",
    "    # First we calculate the number of samples that needs to be generated for each of the datasets that will be mixed into one\n",
    "    number_of_generated_samples = number_of_generated_samples / len(table_of_options)\n",
    "    number_of_generated_samples = int(number_of_generated_samples)\n",
    "    \n",
    "    # we introduce np.arrays in appropriate shape by making them as the first dataset with table_of_options[0] active devices\n",
    "    print(f\"{table_of_options[0]} AD\")\n",
    "    x_tr, x_te, y_tr, y_te, labels = GenerateXXYYL(Dictlist,\n",
    "                                                        sample_length,\n",
    "                                                        table_of_options[0],\n",
    "                                                        dataset_number,\n",
    "                                                        number_of_generated_samples)\n",
    "    \n",
    "    # we rename them for later use if len(table_of_options) > 1\n",
    "    x_train = x_tr\n",
    "    x_test = x_te\n",
    "    y_train = y_tr\n",
    "    y_test = y_te\n",
    "\n",
    "    # we make the rest of the datasets and append them to the first one\n",
    "    for i in range(1,len(table_of_options)):\n",
    "        print(f\"{i+1} AD\")\n",
    "    #    if table_of_options[i] == 0: continue\n",
    "        n_appliances_per_sample = table_of_options[i]\n",
    "        x_tr, x_te, y_tr, y_te, lab = GenerateXXYYL(Dictlist,\n",
    "                                                        sample_length,\n",
    "                                                        n_appliances_per_sample,\n",
    "                                                        dataset_number,\n",
    "                                                        number_of_generated_samples)\n",
    "        x_train = np.append(x_train, x_tr, axis=0)\n",
    "        x_test = np.append(x_test, x_te, axis=0)\n",
    "        y_train = np.append(y_train, y_tr, axis=0)\n",
    "        y_test = np.append(y_test, y_te, axis=0)\n",
    "        \n",
    "        \n",
    "    # we print out the final shapes before returning new datasets\n",
    "    print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)\n",
    "        \n",
    "    \n",
    "    # Now that we have a dataset that consists of len(table_of_options) datasets with different numbers of active devices,\n",
    "    # we just have to make the final dataset that will be made of exactly the same samples but in a random order.\n",
    "    \n",
    "    # To do so first introduce new tables  \n",
    "    tm_train, tm_test = [], []\n",
    "    \n",
    "    # We adjust the number_of_generated_samples back to its original value\n",
    "    number_of_generated_samples = int(number_of_generated_samples*len(table_of_options))\n",
    "    \n",
    "    # we fill tables with integers in order 1,2,3,4,5,6...\n",
    "    \n",
    "    #for m in range(1,int(number_of_generated_samples*0.8)):\n",
    "    for m in range(1,int(math.floor((number_of_generated_samples*0.8)/len(table_of_options))*len(table_of_options)-1)):\n",
    "        tm_train.append(m)\n",
    "    \n",
    "    #for n in range(1,int(number_of_generated_samples*0.2)):\n",
    "    for n in range(1,int(math.floor((number_of_generated_samples*0.2)/len(table_of_options))*len(table_of_options)-1)):\n",
    "        tm_test.append(n)\n",
    "    \n",
    "    # we shuffle the order of those integers so that it is random\n",
    "    random.shuffle(tm_train)\n",
    "    random.shuffle(tm_test)\n",
    "    \n",
    "    # we introduce np.arrays in an appropriate shape\n",
    "    x_train_random = np.empty((0, sample_length, 1))\n",
    "    y_train_random = np.empty((0, len(Dictlist[dataset_number])), dtype=bool)\n",
    "    x_test_random = np.empty((0, sample_length, 1))\n",
    "    y_test_random = np.empty((0, len(Dictlist[dataset_number])), dtype=bool)\n",
    "    \n",
    "    # we concatenate to the arrays by using random order of tm_train\n",
    "    # to make x and y array in the same random order (because we move the same random row in x and y train dataset)\n",
    "    # we split x : y = 80 : 20 like usual\n",
    "    \n",
    "    for g in tqdm(range(0,int(math.floor((number_of_generated_samples*0.8)/len(table_of_options))*len(table_of_options)-3))):\n",
    "        x_applicable = np.expand_dims(x_train[tm_train[g]], axis=0)\n",
    "        y_applicable = np.expand_dims(y_train[tm_train[g]], axis=0)\n",
    "        x_train_random = np.concatenate((x_train_random, x_applicable), axis=0)\n",
    "        y_train_random = np.concatenate((y_train_random, y_applicable), axis=0)\n",
    "\n",
    "    for h in tqdm(range(0,int(math.floor((number_of_generated_samples*0.2)/len(table_of_options))*len(table_of_options)-3))):\n",
    "        x_app = np.expand_dims(x_test[tm_test[h]],axis=0)\n",
    "        y_app = np.expand_dims(y_test[tm_test[h]],axis=0)\n",
    "        x_test_random = np.concatenate((x_test_random, x_app), axis=0)\n",
    "        y_test_random = np.concatenate((y_test_random, y_app), axis=0)\n",
    "\n",
    "    # we print out the final shapes before returning new datasets\n",
    "    print(x_train_random.shape, x_test_random.shape, y_train_random.shape, y_test_random.shape)\n",
    "    \n",
    "    return x_train_random, x_test_random, y_train_random, y_test_random, labels\n",
    "\n",
    "\n",
    "\n",
    "def class_weights_tool(y_test):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function returns class weights for each device in a prticular dataset in a form of a dicitionary.\n",
    "    It does so by simply counting how many times the device is present througout the dataset.\n",
    "    \n",
    "    Args:\n",
    "        y_test (list): the usual y_test part of the dataset, used in ML\n",
    "        \n",
    "    Returns: \n",
    "        class_weights_dictionary (dict): a dictionary which contains a number for each device which represents how many times the device appears in the dataset\n",
    "    \"\"\"\n",
    "    \n",
    "    # inspired by Ronnie Coleman\n",
    "    light_weight, nums = [], []\n",
    "    \n",
    "    # this for loop goes over the collumns of the y_test dataset\n",
    "    for j in range(0,len(y_test[0])):             \n",
    "        \n",
    "        count=0\n",
    "        \n",
    "        # gives 0,1,2,3,4,5,6....\n",
    "        nums.append(j)\n",
    "        \n",
    "        # this loop goes over the rows in the y_test dataset\n",
    "        for i in range(0,len(y_test)):\n",
    "            \n",
    "            # we count Trues in the whole column of y_test dataset\n",
    "            if y_test[i][j] == True: count+=1     \n",
    "        \n",
    "        # we append Trues for the column of y_test dataset to the list light_weight\n",
    "        light_weight.append(count)\n",
    "        \n",
    "    # makes the dictionary    \n",
    "    class_weights_dictionary = dict(zip(nums, light_weight))             \n",
    "    \n",
    "    return class_weights_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "39ee9043-2ac5-407a-8023-5d58e17b4d9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], shape=(0, 15), dtype=bool)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_random = np.empty((0, len(Dictlist[0])), dtype=bool)\n",
    "y_train_random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9b5d70-f13a-4a2d-9439-9201c4f5d156",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Architectures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6afcd3e-5bf7-4cb0-b49e-fd5f87096419",
   "metadata": {},
   "source": [
    "<p>In the next cell there is the code for our proposed architecture CtRNN. If visualized, it would look like this:</p>\n",
    "\n",
    "<img src=\"./notebook_pics/architecture.png\" alt=\"Alt Text\" width=\"720\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d03366d-f2c7-4ff6-9a94-ffbbef31926f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "           CtRNN\n",
    "\"\"\"\n",
    "def CtRNN(classes, window_size):\n",
    "\n",
    "    # Determine proper input shape\n",
    "    input_shape = (window_size,1)\n",
    "    img_input = Input(shape=input_shape)\n",
    "            \n",
    "    # Conv. Block 1\n",
    "    x = Conv1D(64, (3), activation='relu', padding='same', name='block1_conv1')(img_input)\n",
    "    x = Conv1D(64, (3), activation='relu', padding='same', name='block1_conv2')(x)\n",
    "    x = AveragePooling1D((2), strides=(2), name='block1_pool')(x)\n",
    "\n",
    "    # Conv. Block 2\n",
    "    x = Conv1D(128, (3), activation='relu', padding='same', name='block2_conv1')(x)\n",
    "    x = Conv1D(128, (3), activation='relu', padding='same', name='block2_conv2')(x)\n",
    "    x = AveragePooling1D((2), strides=(2), name='block2_pool')(x)\n",
    "\n",
    "    # Conv. Block 3\n",
    "    x = Conv1D(256, (3), activation='relu', padding='same', name='block3_conv1')(x)\n",
    "    x = Conv1D(256, (3), activation='relu', padding='same', name='block3_conv2')(x)\n",
    "    x = AveragePooling1D((2), strides=(2), name='block3_pool')(x)\n",
    "\n",
    "    # Conv. Block 4\n",
    "    x = Conv1D(512, (3), activation='relu', padding='same', name='block4_conv1')(x)\n",
    "    x = Conv1D(512, (3), activation='relu', padding='same', name='block4_conv2')(x)\n",
    "    x = AveragePooling1D((2), strides=(2), name='block4_pool')(x)\n",
    "    \n",
    "    # Trans. conv. \n",
    "    x = Conv1DTranspose(512, (3), activation='relu', padding='same', name='block5_tran_conv1')(x)\n",
    "    x = AveragePooling1D((2), strides=(2), name='block5_pool')(x)\n",
    "    \n",
    "    # GRU layer\n",
    "    x = GRU(64, activation='tanh', recurrent_activation='sigmoid')(x)                \n",
    "\n",
    "    x = Flatten(name='flatten')(x)\n",
    "\n",
    "    # Fully connected layers\n",
    "    x = Dense(4096, activation='relu', name='fc1')(x)\n",
    "    x = Dense(4096, activation='relu', name='fc2')(x)\n",
    "    \n",
    "    # Output\n",
    "    x = Dense(classes, activation='sigmoid', name='predictions')(x)\n",
    "\n",
    "    inputs = img_input\n",
    "\n",
    "    model = Model(inputs, x, name='CtRNN')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70091a3-cb3a-4775-a9f3-f67b2c41c1e8",
   "metadata": {},
   "source": [
    "<p> Up next is the architecture VGG11 adapted to time series. Its just a 1D version of the well known architecture: </p>\n",
    "<img src=\"./notebook_pics/VGG11.png\" alt=\"Alt Text\" width=\"720\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0932cfa2-4094-4cf1-a4e6-9b34ec164641",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "           VGG11 for TS\n",
    "\"\"\"\n",
    "def VGG11_1D(classes,\n",
    "             window_size,\n",
    "             include_top=True,\n",
    "             input_tensor=None,\n",
    "              pooling=None):\n",
    "\n",
    "    # Determine proper input shape\n",
    "    input_shape = (window_size,1)\n",
    "\n",
    "    if input_tensor is None:\n",
    "        img_input = Input(shape=input_shape)\n",
    "    else:\n",
    "        if not K.is_keras_tensor(input_tensor):\n",
    "            img_input = Input(tensor=input_tensor, shape=input_shape)\n",
    "        else:\n",
    "            img_input = input_tensor\n",
    "    # Block 1\n",
    "    x = Conv1D(64, (3), activation='relu', padding='same', name='block1_conv1')(img_input)\n",
    "    x = MaxPooling1D((2), strides=(2), name='block1_pool')(x)\n",
    "\n",
    "    # Block 2\n",
    "    x = Conv1D(128, (3), activation='relu', padding='same', name='block2_conv1')(x)\n",
    "    x = MaxPooling1D((2), strides=(2), name='block2_pool')(x)\n",
    "\n",
    "    # Block 3\n",
    "    x = Conv1D(256, (3), activation='relu', padding='same', name='block3_conv1')(x)\n",
    "    x = Conv1D(256, (3), activation='relu', padding='same', name='block3_conv2')(x)\n",
    "    x = MaxPooling1D((2), strides=(2), name='block3_pool')(x)\n",
    "\n",
    "    # Block 4\n",
    "    x = Conv1D(512, (3), activation='relu', padding='same', name='block4_conv1')(x)\n",
    "    x = Conv1D(512, (3), activation='relu', padding='same', name='block4_conv2')(x)\n",
    "    x = MaxPooling1D((2), strides=(2), name='block4_pool')(x)\n",
    "\n",
    "    # Block 5\n",
    "    x = Conv1D(512, (3), activation='relu', padding='same', name='block5_conv1')(x)\n",
    "    x = Conv1D(512, (3), activation='relu', padding='same', name='block5_conv2')(x)\n",
    "    x = MaxPooling1D((2), strides=(2), name='block5_pool')(x)\n",
    "\n",
    "    if include_top:\n",
    "        # Classification block\n",
    "        x = Flatten(name='flatten')(x)\n",
    "        x = Dense(4096, activation='relu', name='fc1')(x)\n",
    "        x = Dense(4096, activation='relu', name='fc2')(x)\n",
    "        x = Dense(classes, activation='sigmoid', name='predictions')(x)\n",
    "    else:\n",
    "        if pooling == 'avg':\n",
    "            x = GlobalAveragePooling1D()(x)\n",
    "        elif pooling == 'max':\n",
    "            x = GlobalMaxPooling1D()(x)\n",
    "\n",
    "    # Ensure that the model takes into account\n",
    "    # any potential predecessors of `input_tensor`.\n",
    "    if input_tensor is not None:\n",
    "        inputs = get_source_inputs(input_tensor)\n",
    "    else:\n",
    "        inputs = img_input\n",
    "    # Create model.\n",
    "    model = Model(inputs, x, name='vgg11_1D')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a6ff965-cc78-4888-8ec1-1c04ab0785e5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Generating Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c11bdbf-31d3-4512-9aba-bbcea6ed0d2f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## General Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d04c31c-f68f-4ec2-9ef0-af2e8fcb0be4",
   "metadata": {},
   "source": [
    "<p> \n",
    "The following cells must be employed, whether your goal is to generate RE or SE dataset. They load the data, process it and shape it, so that it can be used by RE and SE specific functions. \n",
    "</p>\n",
    "<p>\n",
    "    <strong> Note1: </strong> By default code uses UK-DALE dataset.\n",
    "</p>\n",
    "<p>\n",
    "    <strong> Note2: </strong> The last cell should only be used with UK-DALE dataset.\n",
    "</p>    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "340b9cb9-41f2-4b6b-a85a-df4d2d2b0a69",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boiler 1164\n",
      "solar thermal pumping station 1161\n",
      "laptop computer 1443\n",
      "washer dryer 457\n",
      "dish washer 193\n",
      "television 635\n",
      "light 5771\n",
      "HTPC 120\n",
      "kettle 3621\n",
      "toaster 232\n",
      "fridge freezer 764\n",
      "microwave 554\n",
      "computer monitor 1344\n",
      "audio system 1364\n",
      "breadmaker 110\n",
      "audio amplifier 107\n",
      "broadband router 407\n",
      "soldering iron 195\n",
      "ethernet switch 1361\n",
      "vacuum cleaner 468\n",
      "tablet computer charger 61\n",
      "active subwoofer 30\n",
      "radio 245\n",
      "wireless phone charger 457\n",
      "mobile phone charger 121\n",
      "coffee maker 349\n",
      "hair dryer 567\n",
      "hair straighteners 442\n",
      "clothes iron 79\n",
      "oven 461\n",
      "computer 40\n",
      "baby monitor 59\n",
      "charger 654\n",
      "desktop computer 1339\n",
      "fan 112\n",
      "printer 1090\n",
      "immersion heater 1035\n",
      "active speaker 59\n",
      "external hard disk 10\n",
      "rice cooker 86\n",
      "running machine 83\n",
      "washing machine 128\n",
      "fridge 8\n",
      "games console 9\n",
      "modem 34\n",
      "cooker 45\n",
      "electric space heater 10\n",
      "projector 9\n",
      "freezer 6\n",
      "network attached storage 2\n",
      "server computer 44\n",
      "set top box 62\n",
      "electric oven 6\n",
      "electric stove 6\n"
     ]
    }
   ],
   "source": [
    "#dataset = load_refit_dataset()\n",
    "dataset = load_ukdale_dataset()\n",
    "\n",
    "prepared_data  = data_preparation(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "319a2ed1-d811-4443-b71f-e440754b138b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boiler 804\n",
      "solar thermal pumping station 785\n",
      "laptop computer 1260\n",
      "washer dryer 167\n",
      "dish washer 68\n",
      "television 200\n",
      "light 861\n",
      "HTPC 75\n",
      "kettle 847\n",
      "toaster 156\n",
      "fridge freezer 601\n",
      "microwave 185\n",
      "computer monitor 1212\n",
      "audio system 100\n",
      "breadmaker 33\n",
      "audio amplifier 64\n",
      "broadband router 19\n",
      "soldering iron 8\n",
      "ethernet switch 105\n",
      "vacuum cleaner 465\n",
      "tablet computer charger 28\n",
      "active subwoofer 22\n",
      "radio 44\n",
      "wireless phone charger 42\n",
      "mobile phone charger 41\n",
      "coffee maker 94\n",
      "hair dryer 558\n",
      "hair straighteners 433\n",
      "clothes iron 78\n",
      "oven 116\n",
      "computer 31\n",
      "baby monitor 15\n",
      "charger 92\n",
      "desktop computer 750\n",
      "fan 51\n",
      "printer 363\n",
      "immersion heater 975\n",
      "active speaker 16\n",
      "external hard disk 7\n",
      "rice cooker 12\n",
      "running machine 22\n",
      "washing machine 39\n",
      "fridge 8\n",
      "games console 3\n",
      "modem 13\n",
      "cooker 11\n",
      "electric space heater 7\n",
      "projector 8\n",
      "freezer 5\n",
      "network attached storage 2\n",
      "server computer 19\n",
      "set top box 19\n",
      "electric oven 5\n",
      "electric stove 4\n"
     ]
    }
   ],
   "source": [
    "processed_data = {}\n",
    "\n",
    "for appliance, samples in prepared_data.items():\n",
    "    processed_samples = []\n",
    "    for sample in samples:\n",
    "        sample = sample.resample('7s').ffill(limit=1).fillna(0)\n",
    "        \n",
    "        # It should contain at least one sample\n",
    "        if len(sample) < 2:\n",
    "            continue\n",
    "        \n",
    "        # Filter < 20W\n",
    "        if not np.any(sample.to_numpy() > 20):\n",
    "            continue\n",
    "            \n",
    "        processed_samples.append(sample)\n",
    "        \n",
    "    processed_data[appliance] = list(processed_samples)\n",
    "    \n",
    "processed_data.pop('unknown', None);\n",
    "\n",
    "for k, v in processed_data.items():\n",
    "    print(k, len(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a85d069e-4bff-4bbc-90a4-2c4714424077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Its all good\n"
     ]
    }
   ],
   "source": [
    "#||||||||||||||||||||||||||||||\n",
    "# needed for UK-DALE only\n",
    "#||||||||||||||||||||||||||||||\n",
    "\n",
    "\n",
    "# we do some more editing\n",
    "AllTable111 = [[k,v] for k,v in processed_data.items()]\n",
    "\n",
    "# we delete columns that are present only in values of 'immersion heater', so that we have the last dimension as 1 and not 3\n",
    "try:\n",
    "    for i in range(len(AllTable111[36][1])):\n",
    "        del AllTable111[36][1][i]['power', 'apparent']\n",
    "        del AllTable111[36][1][i]['voltage']\n",
    "except KeyError:\n",
    "    print(\"Its all good\")\n",
    "    \n",
    "# we delete an empty value\n",
    "del AllTable111[36][1][816]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a361e04-8e26-48c4-9e97-6a48e0e662aa",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## RE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0585cd-bc23-41e9-9340-bc1dc589606b",
   "metadata": {},
   "source": [
    "<p> With this code you generate the marked mixed dataset, which has 15 DiT and 1-14 DiT: </p>\n",
    "<img src=\"./notebook_pics/R_heatmap_pic.png\" width=\"180\"/>\n",
    "\n",
    "<p><strong> Warning1: </strong> Because generating this dataset takes a long time we suggest you download already generated one.\n",
    "In the Subsection RE of section Training & Evaluation there is code which will help you upload it into RAM.</p>\n",
    "\n",
    "<p><strong> Warning2: </strong> If you're gonna run this code, have a system with 256GB of RAM. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8d476419-bbde-4e41-a2c1-44f267eafa13",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating datasets with variable active devices ...\n",
      "1 AD\n",
      "2 AD\n",
      "3 AD\n",
      "4 AD\n",
      "5 AD\n",
      "6 AD\n",
      "7 AD\n",
      "8 AD\n",
      "9 AD\n",
      "10 AD\n",
      "11 AD\n",
      "12 AD\n",
      "13 AD\n",
      "14 AD\n",
      "(95984, 2550, 1) (24010, 2550, 1) (95984, 15) (24010, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 95981/95981 [2:47:36<00:00,  9.54it/s]  \n",
      "100%|██████████| 23993/23993 [10:21<00:00, 38.58it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(95981, 2550, 1) (23993, 2550, 1) (95981, 15) (23993, 15)\n"
     ]
    }
   ],
   "source": [
    "window_size = 2550\n",
    "nm_samples = 120_000\n",
    "\n",
    "# EX: 15 DiT, 1-14 AD\n",
    "DiT = 15 # Devices in Total (all devices in the household)\n",
    "table_of_options = [1,2,3,4,5,6,7,8,9,10,11,12,13,14] # All possible options for the number of AD (devices in the household that are active)\n",
    "\n",
    "# In the paper we generated 4 datasets for each combination of DiT and AD, then trained&evaluated 4-times, and took the average weighted average F1 score.\n",
    "# for the purpose of this demo we use only 1\n",
    "nm_sets = 1\n",
    "\n",
    "devicesX_Y, dataX_Y = DevicesDataXY(nm_sets, DiT, 54) #UK-DALE: 54, REFIT: 22\n",
    "Dictlist = ListsToDictlist(devicesX_Y, dataX_Y, nm_sets)\n",
    "\n",
    "for nm in range(0, nm_sets):\n",
    "    x_train, x_test, y_train, y_test, labels = GenerateRandomXXYYL(Dictlist, window_size, nm, table_of_options, nm_samples)\n",
    "    class_weights = class_weights_tool(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f21fd9-789d-4d07-bbdf-634b71d07173",
   "metadata": {},
   "source": [
    "<strong>Example of Completed Datasets</strong>\n",
    "<p>Upon completion of the code, the train and test datasets are expected to exhibit the following structure:</p>\n",
    "<ol>\n",
    "    <li> \n",
    "        <p><strong> x_train </strong> </p>\n",
    "        <img src=\"./notebook_pics/x_train.png\" width=\"480\"/>\n",
    "    </li>\n",
    "    <li> \n",
    "        <p><strong> y_train </strong> </p>\n",
    "        <img src=\"./notebook_pics/y_train.png\" width=\"480\"/>\n",
    "    </li>\n",
    "</ol>\n",
    "<p>Within the datasets <code>x_train</code> and <code>x_test</code>, a time series of length 2550 is observed. Additionally, the datasets <code>y_train</code> and <code>y_test</code> contain arrays of 15 elements (because we have 15 DiT), each representing the device state. The elements are binary, where 1 indicates the device is ON, and 0 indicates the device is OFF.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "1208b05f-5a33-401e-8720-d257b45ba11e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------\n",
      "x_train\n",
      "---------------------------------------------------------------------------\n",
      "2nd sample: \n",
      "Time series: \n",
      "[[220.]\n",
      " [185.]\n",
      " [221.]\n",
      " ...\n",
      " [ 24.]\n",
      " [ 27.]\n",
      " [ 25.]]\n",
      "Plotted time series:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...\n",
      "---------------------------------------------------------------------------\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "---------------------------------------------------------------------------\n",
      "y_train\n",
      "---------------------------------------------------------------------------\n",
      "1st sample:  [ True False  True  True False False False  True  True False False  True\n",
      "  True False False]\n",
      "2nd sample:  [ True  True  True  True  True False  True  True  True  True  True  True\n",
      "  True  True  True]\n",
      "3rd sample:  [False  True False  True False False False False False  True False  True\n",
      "  True False False]\n",
      "4th sample:  [False False  True  True False  True False  True False  True False False\n",
      " False False  True]\n",
      "...\n",
      "---------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"---------------------------------------------------------------------------\")\n",
    "print(\"x_train\")\n",
    "print(\"---------------------------------------------------------------------------\")\n",
    "print(\"2nd sample: \")\n",
    "print(\"Time series: \")\n",
    "print(x_train[1])\n",
    "print(\"Plotted time series:\")\n",
    "plt.plot(x_train[1])\n",
    "plt.show()\n",
    "print(\"...\")\n",
    "print(\"---------------------------------------------------------------------------\")\n",
    "print(\"|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\")\n",
    "print(\"---------------------------------------------------------------------------\")\n",
    "print(\"y_train\")\n",
    "print(\"---------------------------------------------------------------------------\")\n",
    "print(\"1st sample: \", y_train[0])\n",
    "print(\"2nd sample: \", y_train[1])\n",
    "print(\"3rd sample: \", y_train[2])\n",
    "print(\"4th sample: \", y_train[3])\n",
    "print(\"...\")\n",
    "print(\"---------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51f8f29-71e7-4dfb-9c28-6c9e5fc8fc6c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## SE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda4f746-29e5-4951-81f4-96ed70c8b809",
   "metadata": {},
   "source": [
    "<p> With this code you generate the marked mixed dataset which has 15 DiT and 11 AD: </p>\n",
    "<img src=\"./notebook_pics/heatmap_pic.png\" alt=\"Alt Text\" width=\"720\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "dd0f7a76-2623-46e9-a340-2e32194b133d",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size=2550\n",
    "nm_samples = 120_000\n",
    "\n",
    "# EX: 15 DiT, 11 AD\n",
    "DiT = 15 # Devices in Total (all devices in the household)\n",
    "AD = 11  # Active Devices (devices in the household that are active)\n",
    "\n",
    "# In the paper we generated 4 datasets for each of the blocks to get a more accurate score, \n",
    "# for the purpose of this demo we use only 1\n",
    "nm_sets = 1\n",
    "\n",
    "devicesX_Y, dataX_Y = DevicesDataXY(nm_sets, DiT, 54) #UK-DALE: 54, REFIT: 22\n",
    "Dictlist = ListsToDictlist(devicesX_Y, dataX_Y, nm_sets)\n",
    "\n",
    "for nm in range(0, nm_sets):\n",
    "    x_train, x_test, y_train, y_test, labels = GenerateXXYYL(Dictlist, window_size, AD, nm, nm_samples)\n",
    "    class_weights = class_weights_tool(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9311a045-d9ff-4e2b-bd1d-253bfde72087",
   "metadata": {},
   "source": [
    "<strong>Example of Completed Datasets</strong>\n",
    "<p>Upon completion of the code, the train and test datasets are expected to exhibit the following structure:</p>\n",
    "<ol>\n",
    "    <li> \n",
    "        <p><strong> x_train </strong> </p>\n",
    "        <img src=\"./notebook_pics/x_train_SE.png\" width=\"480\"/>\n",
    "    </li>\n",
    "    <li> \n",
    "        <p><strong> y_train </strong> </p>\n",
    "        <img src=\"./notebook_pics/y_train_SE.png\" width=\"480\"/>\n",
    "    </li>\n",
    "</ol>\n",
    "<p>Within the datasets <code>x_train</code> and <code>x_test</code>, a time series of length 2550 is observed. Additionally, the datasets <code>y_train</code> and <code>y_test</code> contain arrays of 15 elements (because we have 15 DiT), each representing the device state. The elements are binary, where \"True\" indicates the device is ON, and \"False\" indicates the device is OFF.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "be6685f7-bbb2-4233-b5ec-c86d26577344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------\n",
      "x_train\n",
      "---------------------------------------------------------------------------\n",
      "1st sample: \n",
      "Time series: \n",
      "[[ 17.]\n",
      " [ 17.]\n",
      " [ 17.]\n",
      " ...\n",
      " [423.]\n",
      " [438.]\n",
      " [408.]]\n",
      "Plotted time series:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...\n",
      "---------------------------------------------------------------------------\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "---------------------------------------------------------------------------\n",
      "y_train\n",
      "---------------------------------------------------------------------------\n",
      "1st sample:  [ True  True  True  True False  True False False  True  True  True  True\n",
      "  True False  True]\n",
      "2nd sample:  [ True  True  True False  True  True False  True  True  True False  True\n",
      " False  True  True]\n",
      "3rd sample:  [ True  True  True  True False  True False  True  True  True  True  True\n",
      " False False  True]\n",
      "4th sample:  [ True False  True False  True  True  True False  True False  True  True\n",
      "  True  True  True]\n",
      "...\n",
      "---------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"---------------------------------------------------------------------------\")\n",
    "print(\"x_train\")\n",
    "print(\"---------------------------------------------------------------------------\")\n",
    "print(\"1st sample: \")\n",
    "print(\"Time series: \")\n",
    "print(x_train[0])\n",
    "print(\"Plotted time series:\")\n",
    "plt.plot(x_train[0])\n",
    "plt.show()\n",
    "print(\"...\")\n",
    "print(\"---------------------------------------------------------------------------\")\n",
    "print(\"|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\")\n",
    "print(\"---------------------------------------------------------------------------\")\n",
    "print(\"y_train\")\n",
    "print(\"---------------------------------------------------------------------------\")\n",
    "print(\"1st sample: \", y_train[0])\n",
    "print(\"2nd sample: \", y_train[1])\n",
    "print(\"3rd sample: \", y_train[2])\n",
    "print(\"4th sample: \", y_train[3])\n",
    "print(\"...\")\n",
    "print(\"---------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b893590-0a24-4269-aa0c-f1b526788892",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Training & Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8eae8b8-2404-40f8-addc-a0c9b2e8608e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## RE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f095a5-fa8e-4a37-ac81-35821393a545",
   "metadata": {},
   "source": [
    "<p> This example corresponds to this cell in the heatmap: </p>\n",
    "<img src=\"./notebook_pics/R_heatmap_pic.png\" width=\"180\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f0a04ad7-4d49-4cdb-b68c-768df1170356",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"CtRNN\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 2550, 1)]         0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv1D)       (None, 2550, 64)          256       \n",
      "                                                                 \n",
      " block1_conv2 (Conv1D)       (None, 2550, 64)          12352     \n",
      "                                                                 \n",
      " block1_pool (AveragePoolin  (None, 1275, 64)          0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " block2_conv1 (Conv1D)       (None, 1275, 128)         24704     \n",
      "                                                                 \n",
      " block2_conv2 (Conv1D)       (None, 1275, 128)         49280     \n",
      "                                                                 \n",
      " block2_pool (AveragePoolin  (None, 637, 128)          0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " block3_conv1 (Conv1D)       (None, 637, 256)          98560     \n",
      "                                                                 \n",
      " block3_conv2 (Conv1D)       (None, 637, 256)          196864    \n",
      "                                                                 \n",
      " block3_pool (AveragePoolin  (None, 318, 256)          0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " block4_conv1 (Conv1D)       (None, 318, 512)          393728    \n",
      "                                                                 \n",
      " block4_conv2 (Conv1D)       (None, 318, 512)          786944    \n",
      "                                                                 \n",
      " block4_pool (AveragePoolin  (None, 159, 512)          0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " block5_tran_conv1 (Conv1DT  (None, 159, 512)          786944    \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " block5_pool (AveragePoolin  (None, 79, 512)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " gru_1 (GRU)                 (None, 64)                110976    \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 64)                0         \n",
      "                                                                 \n",
      " fc1 (Dense)                 (None, 4096)              266240    \n",
      "                                                                 \n",
      " fc2 (Dense)                 (None, 4096)              16781312  \n",
      "                                                                 \n",
      " predictions (Dense)         (None, 15)                61455     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19569615 (74.65 MB)\n",
      "Trainable params: 19569615 (74.65 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "750/750 [==============================] - 30s 37ms/step - loss: inf - accuracy: 0.2569\n",
      "Epoch 2/20\n",
      "750/750 [==============================] - 27s 36ms/step - loss: inf - accuracy: 0.4287\n",
      "Epoch 3/20\n",
      "750/750 [==============================] - 27s 36ms/step - loss: inf - accuracy: 0.4588\n",
      "Epoch 4/20\n",
      "750/750 [==============================] - 27s 36ms/step - loss: inf - accuracy: 0.4597\n",
      "Epoch 5/20\n",
      "750/750 [==============================] - 27s 36ms/step - loss: inf - accuracy: 0.4798\n",
      "Epoch 6/20\n",
      "750/750 [==============================] - 27s 36ms/step - loss: inf - accuracy: 0.4874\n",
      "Epoch 7/20\n",
      "750/750 [==============================] - 27s 36ms/step - loss: inf - accuracy: 0.5171\n",
      "Epoch 8/20\n",
      "750/750 [==============================] - 27s 36ms/step - loss: inf - accuracy: 0.5404\n",
      "Epoch 9/20\n",
      "750/750 [==============================] - 27s 36ms/step - loss: inf - accuracy: 0.5559\n",
      "Epoch 10/20\n",
      "750/750 [==============================] - 27s 36ms/step - loss: inf - accuracy: 0.5825\n",
      "Epoch 11/20\n",
      "750/750 [==============================] - 27s 36ms/step - loss: inf - accuracy: 0.5999\n",
      "Epoch 12/20\n",
      "750/750 [==============================] - 27s 37ms/step - loss: inf - accuracy: 0.6251\n",
      "Epoch 13/20\n",
      "750/750 [==============================] - 27s 36ms/step - loss: inf - accuracy: 0.6540\n",
      "Epoch 14/20\n",
      "750/750 [==============================] - 27s 37ms/step - loss: inf - accuracy: 0.6640\n",
      "Epoch 15/20\n",
      "750/750 [==============================] - 27s 36ms/step - loss: inf - accuracy: 0.6850\n",
      "Epoch 16/20\n",
      "750/750 [==============================] - 27s 36ms/step - loss: inf - accuracy: 0.7035\n",
      "Epoch 17/20\n",
      "750/750 [==============================] - 27s 36ms/step - loss: inf - accuracy: 0.7180\n",
      "Epoch 18/20\n",
      "750/750 [==============================] - 27s 36ms/step - loss: inf - accuracy: 0.7301\n",
      "Epoch 19/20\n",
      "750/750 [==============================] - 27s 36ms/step - loss: inf - accuracy: 0.7433\n",
      "Epoch 20/20\n",
      "750/750 [==============================] - 27s 36ms/step - loss: inf - accuracy: 0.7542\n",
      "750/750 [==============================] - 4s 5ms/step\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "            clothes iron       0.99      0.99      0.99     12004\n",
      "  wireless phone charger       0.83      0.81      0.82     11963\n",
      "             set top box       0.90      0.88      0.89     12003\n",
      "              hair dryer       0.98      0.98      0.98     12140\n",
      "                    HTPC       0.96      0.93      0.94     11965\n",
      "          active speaker       0.79      0.87      0.83     11889\n",
      "network attached storage       0.93      0.97      0.95     11984\n",
      "        desktop computer       0.89      0.83      0.86     11941\n",
      "              television       0.86      0.84      0.85     11967\n",
      "                 toaster       0.97      0.92      0.94     12088\n",
      "             rice cooker       0.99      0.99      0.99     12005\n",
      "                  cooker       0.76      0.84      0.80     11971\n",
      " tablet computer charger       0.86      0.89      0.87     12037\n",
      "          soldering iron       0.91      0.91      0.91     11971\n",
      "      external hard disk       0.79      0.87      0.83     11926\n",
      "\n",
      "               micro avg       0.89      0.90      0.90    179854\n",
      "               macro avg       0.89      0.90      0.90    179854\n",
      "            weighted avg       0.89      0.90      0.90    179854\n",
      "             samples avg       0.90      0.89      0.89    179854\n",
      "\n"
     ]
    }
   ],
   "source": [
    "BS = 128\n",
    "LR = 0.0003\n",
    "E = 20\n",
    "\n",
    "DiT = 15\n",
    "window_size = 2550\n",
    "\n",
    "# Using the saved dataset\n",
    "#saved_dataset = pickle.load(open('path','rb'))\n",
    "#x_train, x_test, y_train, y_test, labels = saved_dataset[0], saved_dataset[1], saved_dataset[2], saved_dataset[3], saved_dataset[4]\n",
    "class_weights = class_weights_tool(y_test)\n",
    "\n",
    "# |||||||||||||||||||||||||||||||| training ||||||||||||||||||||||||||||||||\n",
    "model = CtRNN(DiT, window_size)\n",
    "model.build((len(y_train)+len(y_test),window_size,1))\n",
    "model.summary()\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=LR),loss='binary_crossentropy',metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, batch_size=BS, epochs=E, class_weight=class_weights)\n",
    "# |||||||||||||||||||||||||||||||| prediction ||||||||||||||||||||||||||||||||\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred_tf = (y_pred > 0.5)\n",
    "# |||||||||||||||||||||||||||||||| evaluation ||||||||||||||||||||||||||||||||\n",
    "print(metrics.classification_report(y_test, y_pred_tf, target_names=labels, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b590daa5-7b0f-46b3-b17d-ddba8f9694af",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## SE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaeaea43-904b-4749-b619-4bc975a94a76",
   "metadata": {},
   "source": [
    "<p> This example corresponds to this cell in the heatmap: </p>\n",
    "\n",
    "<img src=\"./notebook_pics/heatmap_pic.png\" width=\"480\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6a8501fa-9359-4985-88ad-2613ff328ffd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "750/750 [==============================] - 31s 38ms/step - loss: inf - accuracy: 0.0268\n",
      "Epoch 2/20\n",
      "750/750 [==============================] - 27s 36ms/step - loss: inf - accuracy: 0.0212\n",
      "Epoch 3/20\n",
      "750/750 [==============================] - 27s 36ms/step - loss: inf - accuracy: 0.0235\n",
      "Epoch 4/20\n",
      "750/750 [==============================] - 27s 36ms/step - loss: inf - accuracy: 0.0260\n",
      "Epoch 5/20\n",
      "750/750 [==============================] - 27s 36ms/step - loss: inf - accuracy: 0.0324\n",
      "Epoch 6/20\n",
      "750/750 [==============================] - 27s 36ms/step - loss: inf - accuracy: 0.0446\n",
      "Epoch 7/20\n",
      "750/750 [==============================] - 27s 36ms/step - loss: inf - accuracy: 0.0594\n",
      "Epoch 8/20\n",
      "750/750 [==============================] - 27s 36ms/step - loss: inf - accuracy: 0.0791\n",
      "Epoch 9/20\n",
      "750/750 [==============================] - 27s 36ms/step - loss: inf - accuracy: 0.1170\n",
      "Epoch 10/20\n",
      "750/750 [==============================] - 27s 36ms/step - loss: inf - accuracy: 0.1482\n",
      "Epoch 11/20\n",
      "750/750 [==============================] - 27s 36ms/step - loss: inf - accuracy: 0.1988\n",
      "Epoch 12/20\n",
      "750/750 [==============================] - 27s 36ms/step - loss: inf - accuracy: 0.2364\n",
      "Epoch 13/20\n",
      "750/750 [==============================] - 27s 36ms/step - loss: inf - accuracy: 0.2792\n",
      "Epoch 14/20\n",
      "750/750 [==============================] - 27s 36ms/step - loss: inf - accuracy: 0.3146\n",
      "Epoch 15/20\n",
      "750/750 [==============================] - 27s 36ms/step - loss: inf - accuracy: 0.3542\n",
      "Epoch 16/20\n",
      "750/750 [==============================] - 27s 36ms/step - loss: inf - accuracy: 0.3893\n",
      "Epoch 17/20\n",
      "750/750 [==============================] - 27s 36ms/step - loss: inf - accuracy: 0.4264\n",
      "Epoch 18/20\n",
      "750/750 [==============================] - 27s 36ms/step - loss: inf - accuracy: 0.4575\n",
      "Epoch 19/20\n",
      "750/750 [==============================] - 27s 36ms/step - loss: inf - accuracy: 0.4949\n",
      "Epoch 20/20\n",
      "750/750 [==============================] - 27s 36ms/step - loss: inf - accuracy: 0.5241\n",
      "750/750 [==============================] - 4s 5ms/step\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "              microwave       0.91      0.88      0.89     17607\n",
      "                   HTPC       0.86      0.92      0.89     17692\n",
      "                freezer       0.98      0.99      0.98     17479\n",
      "                toaster       0.92      0.89      0.90     17582\n",
      "        ethernet switch       0.93      0.91      0.92     17566\n",
      "           clothes iron       0.98      0.97      0.97     17613\n",
      "                 kettle       0.86      0.87      0.87     17623\n",
      "               computer       0.89      0.96      0.92     17755\n",
      "         electric stove       0.99      0.99      0.99     17545\n",
      "          electric oven       0.98      0.98      0.98     17534\n",
      " wireless phone charger       0.80      0.89      0.84     17662\n",
      "                   oven       0.88      0.89      0.89     17554\n",
      "             breadmaker       0.92      0.90      0.91     17648\n",
      "tablet computer charger       0.82      0.87      0.85     17582\n",
      "       immersion heater       0.90      0.91      0.90     17558\n",
      "\n",
      "              micro avg       0.91      0.92      0.91    264000\n",
      "              macro avg       0.91      0.92      0.91    264000\n",
      "           weighted avg       0.91      0.92      0.91    264000\n",
      "            samples avg       0.91      0.92      0.91    264000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Parameters according to the table 2.\n",
    "BS = 128\n",
    "LR = 0.0005\n",
    "E = 20\n",
    "\n",
    "# |||||||||||||||||||||||||||||||| training ||||||||||||||||||||||||||||||||\n",
    "model = CtRNN(DiT, window_size)\n",
    "model.build((len(y_train)+len(y_test),window_size,1))\n",
    "#model.summary()\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=LR),loss='binary_crossentropy',metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, batch_size=BS, epochs=E, class_weight=class_weights)\n",
    "# |||||||||||||||||||||||||||||||| prediction ||||||||||||||||||||||||||||||||\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred_tf = (y_pred > 0.5)\n",
    "# |||||||||||||||||||||||||||||||| evaluation ||||||||||||||||||||||||||||||||\n",
    "print(metrics.classification_report(y_test, y_pred_tf, target_names=labels, zero_division=0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
